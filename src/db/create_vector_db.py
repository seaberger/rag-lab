# --- START OF create_vector_db.py ---
import os
import pickle
import logging
import time
from pathlib import Path
from dotenv import load_dotenv
from llama_index.core import VectorStoreIndex, StorageContext, Settings
from llama_index.vector_stores.qdrant import QdrantVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
from tqdm import tqdm
from qdrant_client import QdrantClient
from qdrant_client.http.models import Distance, VectorParams

# --- Configuration ---

# <<<--- CHANGE THIS LINE ---<<<
# Path to the nodes generated by metadata.py
NODES_PICKLE_FILE = "./data/nodes/matrix_nodes.pkl"  # Assuming this path is correct relative to the script's location
# >>>------------------------->>>

# Directory where Qdrant DB files will be stored LOCALLY (keep targeting the deployment folder)
LOCAL_QDRANT_PATH = "./matrix_chatbot/qdrant_db"
# Name for the Qdrant collection
QDRANT_COLLECTION_NAME = "matrix_docs"
# OpenAI Embedding Model
EMBEDDING_MODEL = "text-embedding-3-large"
# Vector size for the chosen model
VECTOR_SIZE = 3072
# --- End Configuration ---

# Setup logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(module)s - %(message)s"
)


def create_persistent_qdrant_db():
    """Loads nodes, embeds if necessary, creates a persistent Qdrant DB, and verifies."""

    # --- Load API Keys ---
    logging.info("Loading environment variables...")
    # ... (rest of API key loading) ...
    if not load_dotenv():
        logging.warning("Could not load .env file.")
    openai_api_key = os.environ.get("OPENAI_API_KEY")
    if not openai_api_key:
        logging.error("Fatal: OPENAI_API_KEY not found.")
        raise ValueError("OPENAI_API_KEY must be set.")

    # --- Initialize Embedding Model ---
    logging.info(f"Initializing embedding model: {EMBEDDING_MODEL}")
    # ... (rest of embedding model init) ...
    try:
        embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL, api_key=openai_api_key)
        Settings.embed_model = embed_model
    except Exception as e:
        logging.error(f"Failed to init embedding model: {e}")
        raise

    # --- Load Nodes ---
    nodes_path = Path(NODES_PICKLE_FILE)  # Uses the updated path
    # ... (rest of node loading and checks) ...
    if not nodes_path.exists():
        logging.error(f"Fatal: Node file not found: {nodes_path}")
        raise FileNotFoundError(f"Node file not found: {nodes_path}")
    logging.info(f"Loading nodes from {nodes_path}...")
    with open(nodes_path, "rb") as f:
        nodes = pickle.load(f)
    logging.info(f"Loaded {len(nodes)} nodes.")
    if not nodes:
        logging.warning("Node file is empty.")
        return

    # --- Check/Generate Embeddings ---
    has_existing_embeddings = False
    # ... (same logic as before to check first node's embedding) ...
    first_node_embedding = getattr(nodes[0], "embedding", None)
    if first_node_embedding is not None and isinstance(first_node_embedding, list):
        if len(first_node_embedding) == VECTOR_SIZE:
            logging.info(
                f"Nodes appear to have existing embeddings of correct dimension ({VECTOR_SIZE})."
            )
            has_existing_embeddings = True
        else:
            logging.warning(
                f"Nodes have existing embeddings, dimension ({len(first_node_embedding)}) != target ({VECTOR_SIZE}). Re-embedding."
            )
    else:
        logging.info("Nodes need new embeddings.")

    if not has_existing_embeddings:
        logging.info(
            f"Starting explicit embedding generation for {len(nodes)} nodes..."
        )
        embedding_errors = 0
        for node in tqdm(nodes, desc="Generating Embeddings"):
            try:
                node_content = (
                    node.get_content()
                )  # Or node.get_content(metadata_mode="all")
                node.embedding = embed_model.get_text_embedding(node_content)
                if len(node.embedding) != VECTOR_SIZE:
                    logging.warning(
                        f"Generated embedding for node {node.node_id or 'Unknown'} has incorrect dimension: {len(node.embedding)}"
                    )
                    embedding_errors += 1
            except Exception as e:
                logging.error(f"Failed to embed node {node.node_id or 'Unknown'}: {e}")
                node.embedding = None
                embedding_errors += 1
        logging.info(
            f"Finished explicit embedding generation. Errors: {embedding_errors}"
        )
        if embedding_errors > 0:
            logging.warning("Some nodes failed to embed.")
        has_existing_embeddings = True  # Mark true now

    # --- Setup Qdrant Client and Store ---
    qdrant_path = Path(LOCAL_QDRANT_PATH)  # Keep output path the same
    # ... (rest of Qdrant client setup) ...
    qdrant_path.mkdir(parents=True, exist_ok=True)
    logging.info(f"Initializing Qdrant client (persistent): {qdrant_path}")
    client = QdrantClient(path=str(qdrant_path))

    # --- Manage Qdrant Collection ---
    # ... (rest of collection recreation logic) ...
    try:
        collections = client.get_collections().collections
        if any(c.name == QDRANT_COLLECTION_NAME for c in collections):
            logging.warning(f"Recreating existing collection: {QDRANT_COLLECTION_NAME}")
            client.delete_collection(collection_name=QDRANT_COLLECTION_NAME)
        logging.info(
            f"Creating collection '{QDRANT_COLLECTION_NAME}' (Size: {VECTOR_SIZE})"
        )
        client.create_collection(
            collection_name=QDRANT_COLLECTION_NAME,
            vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE),
        )
    except Exception as e:
        logging.error(f"Error managing Qdrant collection: {e}")
        raise

    vector_store = QdrantVectorStore(
        client=client, collection_name=QDRANT_COLLECTION_NAME
    )
    storage_context = StorageContext.from_defaults(vector_store=vector_store)

    # --- Populate Qdrant ---
    logging.info("Populating Qdrant using VectorStoreIndex...")
    nodes_to_index = [n for n in nodes if n.embedding is not None]
    if not nodes_to_index:
        logging.error("No nodes with valid embeddings to index!")
        return
    logging.info(f"Attempting to index {len(nodes_to_index)} nodes...")
    # ... (rest of VectorStoreIndex population logic, using embed_model=None) ...
    try:
        index = VectorStoreIndex(
            nodes_to_index,
            storage_context=storage_context,
            embed_model=None,
            show_progress=True,
        )
        logging.info(
            f"VectorStoreIndex population step completed for {len(index.docstore.docs)} docs."
        )
    except Exception as e:
        logging.error(f"Error during VectorStoreIndex population: {e}", exc_info=True)
        raise

    # --- Verification Step ---
    # ... (rest of verification logic) ...
    logging.info("--- Verifying data in Qdrant ---")
    try:
        count_result = client.count(collection_name=QDRANT_COLLECTION_NAME, exact=True)
        num_points = count_result.count
        logging.info(f"Qdrant point count: {num_points}")
        if num_points != len(nodes_to_index):
            logging.warning(f"Point count mismatch!")
        if num_points > 0:
            logging.info("Retrieving sample points with vectors...")
            scroll_result, _ = client.scroll(
                collection_name=QDRANT_COLLECTION_NAME,
                limit=5,
                with_payload=True,
                with_vectors=True,
            )
            logging.info(f"Retrieved {len(scroll_result)} sample points.")
            vectors_found = 0
            correct_dimension = 0
            for i, point in enumerate(scroll_result):
                # ... (logging point details) ...
                is_vector_none = point.vector is None
                vector_len = len(point.vector) if point.vector is not None else 0
                logging.info(
                    f"  Sample Point {i}: ID={point.id}, Vector None? {is_vector_none}, Length: {vector_len}"
                )
                if not is_vector_none:
                    vectors_found += 1
                if vector_len == VECTOR_SIZE:
                    correct_dimension += 1
            logging.info(
                f"Verification Summary: Found vectors: {vectors_found}/{len(scroll_result)}. Correct dimension: {correct_dimension}/{vectors_found}."
            )
            if vectors_found == 0 or correct_dimension != vectors_found:
                logging.error("!!! Verification Failed: Vector issues in Qdrant! !!!")
            else:
                logging.info("Verification Passed: Sample vectors look okay.")
        else:
            logging.warning("Verification Skipped: Collection empty.")
    except Exception as e:
        logging.error(f"Error during verification: {e}", exc_info=True)

    logging.info("--- Qdrant database creation script finished ---")


if __name__ == "__main__":
    create_persistent_qdrant_db()
# --- END OF FILE create_vector_db.py ---
