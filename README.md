# ğŸ“š Datasheet Ingestion Pipeline

A production-ready ETL pipeline that ingests PDF datasheets and Markdown documents into a searchable vector database with hybrid search capabilities.

## âœ¨ Key Features

- **Multi-format Support**: PDF datasheets, generic PDFs, and Markdown files
- **Intelligent Parsing**: 
  - Extracts model/part number pairs from datasheets using OpenAI Vision API
  - Direct Markdown ingestion without API calls
- **Hybrid Search**: Combines vector embeddings (semantic) with BM25 (keyword) search
- **Production Ready**: Caching, progress tracking, error handling, and retry logic
- **Cost Optimized**: Disk-based caching to avoid redundant API calls

## ğŸš€ Quick Start

### Prerequisites

```bash
# Install dependencies
pip install -r requirements.txt

# Install Poppler for PDF processing
# macOS
brew install poppler
# Ubuntu  
sudo apt-get install poppler-utils

# Set OpenAI API key
export OPENAI_API_KEY="sk-..."
```

### Basic Usage

```bash
# Process PDF datasheets with keyword augmentation
python datasheet_ingest_pipeline.py --src *.pdf --with_keywords

# Process mixed document types
python datasheet_ingest_pipeline.py --src docs/*.pdf docs/*.md

# Search the indexed documents
python search_cli.py "PM10K laser sensor" --mode hybrid --limit 10
```

## ğŸ“ Project Structure

```
datasheet-ingestion-pipeline/
â”œâ”€â”€ datasheet_ingest_pipeline.py    # Main pipeline
â”œâ”€â”€ search_cli.py                   # Search interface
â”œâ”€â”€ hybrid_search.py                # Combined search
â”œâ”€â”€ keyword_index.py                # BM25 indexing
â”œâ”€â”€ cache_manager.py                # Document caching
â”œâ”€â”€ progress_monitor.py             # Progress tracking
â”œâ”€â”€ config.yaml                     # Configuration
â”œâ”€â”€ artefacts/                      # Processed documents
â”œâ”€â”€ qdrant_data/                    # Vector embeddings
â””â”€â”€ cache/                          # Cached parsed docs
```

## ğŸ”§ Configuration

Edit `config.yaml` to customize:

- API models and retry settings
- Cache and batch processing options
- File size and validation limits
- Search parameters

## ğŸ“Š Data Flow

```
PDF/Markdown â†’ Parse â†’ Extract Pairs â†’ Chunk â†’ Keywords â†’ Embed â†’ Index â†’ Search
```

## ğŸ” Search Modes

- **Hybrid**: Combines vector and keyword search (recommended)
- **Vector**: Semantic search using embeddings
- **Keyword**: BM25 full-text search

## ğŸ“ Example Usage

```bash
# Batch process from file list
python datasheet_ingest_pipeline.py --src @urls.txt --with_keywords

# Search by part number
python search_cli.py "2293937" --mode keyword

# Semantic concept search
python search_cli.py "high precision optical measurement" --mode vector
```

## ğŸ›  Requirements

- Python 3.8+
- OpenAI API key
- Poppler utilities
- 2GB+ disk space for vector storage

## ğŸ“– Documentation

See the documentation files for detailed information:
- `datasheet_ingest_overview.md` - Pipeline architecture
- `updated_document_ingestion_pipeline.md` - Enhanced features

## ğŸ“„ License

[MIT](https://choosealicense.com/licenses/mit/)

---

**Note**: This pipeline is optimized for technical datasheets but works with any PDF or Markdown content.